---
layout: page
title:  Getting, scraping, cleaning data
---


To download for class

* [import.io](https://import.io/download/)
* [Google Open Refine](http://openrefine.org/)
* [Data Scraper Chrome Extension](https://chrome.google.com/webstore/detail/data-scraper/nndknepjnldbdbepjfgmncbggmopgden?hl=en-US)

### Links for class
* [Finding official data]({{ site.url }}/class7/class7.html)
* [Cleaning up data with Open Refine]({{ site.url }}/class7/openrefine)
* [Scraping data with Data Miner]({{ site.url }}/class7/scraping_intro)
* [Scraping data with Import.io]({{ site.url }}/class7/importio)

*A note about data cleaning and scraping*

I know this can all seem overwhelming. These are introductions to new tools every week.

Keep in mind:

* Don't get lost in the bog of tools and techniques to master.
* What problem does this tool solve?
* Data is dirty and finicky and difficult
 * 75 percent of working with data is finding it, transforming it, before you can analyze or visualize it.
* It's not about the tools or the cool gadgets. 
 * **It's about the story.**

## Notes on the Midterm due October 21

Obtain and analyze federal government data and write a summary of the analysis. 

Not the actual story. 

Instead, the memo should detail the process it will take to get to the final story or visualization. 

 * For an example of the level detail I'll be looking for, check out my list under [Homework 2 from Class 6]({{ site.url }}/2015/10/07/joining-data/)

Explain what it took to get the data, who explained it to you, point out the nuances and limitations of it and how it was collected or processed. 

Discuss the gaps in tha data and what could be improved. Then, analyze the agency that provided the data set. 

Detail the scope, quality, and accesibility of the rest of the department's data. 

How journalists might have used it so far or how it could be used in the future.

Length: 1,000 words.
